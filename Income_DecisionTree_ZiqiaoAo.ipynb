{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Income_DecisionTree_ZiqiaoAo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BonnieAo/ECON211-Week2-Decision-Tree/blob/main/Income_DecisionTree_ZiqiaoAo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB0sNYDCJ0M0"
      },
      "source": [
        "# Step 1: Data Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIsslb8YINKh"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\r\n",
        "from sklearn import metrics \r\n",
        "clf = DecisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTM-a9GZIWRL"
      },
      "source": [
        "###show all columns\r\n",
        "pd.set_option('display.max_columns', None)\r\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH8NDdVFImVZ"
      },
      "source": [
        "df=pd.read_csv('https://raw.githubusercontent.com/BonnieAo/ECON211-Week2-Decision-Tree/main/adult.csv')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVY7Pn_rTlVt"
      },
      "source": [
        "###deal with missing values and unresonable values\n",
        "df = df[(df != '?').all(axis=1)]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWPv9z8dWJFW"
      },
      "source": [
        "df['income']=df['income'].apply(lambda x: '<=50K' if x== '<=50K' else '>50K')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO7AMn6xU6S8"
      },
      "source": [
        "df['sex_num']=df['sex'].apply(lambda x: 1 if x== 'Female' else 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X-FGZ1pWPwp"
      },
      "source": [
        "df['race_num']=df['race'].apply(lambda x: 1 if x== 'White' else 2 if x== 'Other' else 3 if x== 'Asian-Pac-Islander' else 4 if x== 'Amer-Indian-Eskimo' else 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXfdY-ZcJ3pu"
      },
      "source": [
        "# Build Decision Tree with One Feature for Writing Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch9KDctHJwMk"
      },
      "source": [
        "#feature_names=['race_num','sex_num','education.num']\r\n",
        "feature_names=['education.num']\r\n",
        "#feature_names=['race_num','sex_num','education.num','age','capital.gain','capital.loss']\r\n",
        "features=df[feature_names]\r\n",
        "targets=df['income']\r\n",
        "targets_names = targets.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvEGwTwJWl1F"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, cross_val_score,KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhvd1N3HcHpP"
      },
      "source": [
        "### Find the max_depth using cross validation score\n",
        "ScoreAll = []\n",
        "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
        "for i in range(1, 20):\n",
        "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=i, random_state=42)\n",
        "    score = cross_val_score(clf, features, targets, cv=cv).mean()\n",
        "    ScoreAll.append([i, score])\n",
        "ScoreAll = np.array(ScoreAll)\n",
        "max_score = np.where(ScoreAll==np.max(ScoreAll[:, 1]))[0][0]\n",
        "optimal_max_depth = ScoreAll[np.where(ScoreAll==np.max(ScoreAll[:, 1]))[0][0]][0]\n",
        "print(\"optimal max_depth and max score:\", ScoreAll[max_score])\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=[20, 5])\n",
        "plt.plot(ScoreAll[:, 0], ScoreAll[:, 1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M83RDrL0_3a"
      },
      "source": [
        "###training & test data split\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "train_features, test_features, train_targets, test_targets = train_test_split(features, targets, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcMhGaehLC_y"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhVIHZN6LEuj"
      },
      "source": [
        "#####Optimizing Decision Tree Performance\r\n",
        "# Create Decision Tree classifer object\r\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth = optimal_max_depth,random_state=42)\r\n",
        "\r\n",
        "# Train Decision Tree Classifer\r\n",
        "clf = clf.fit(train_features,train_targets)\r\n",
        "\r\n",
        "#Predict the response for test dataset\r\n",
        "y_pred = clf.predict(test_features)\r\n",
        "\r\n",
        "# Compute test set accuracy  \r\n",
        "acc = accuracy_score(y_pred, test_targets)\r\n",
        "print(\"Test set accuracy: {:.4f}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n4BxXMALGm5"
      },
      "source": [
        "from sklearn.tree import export_graphviz\r\n",
        "from sklearn.externals.six import StringIO  \r\n",
        "from IPython.display import Image  \r\n",
        "import pydotplus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cliGo7ZKLKr5"
      },
      "source": [
        "### Plot the figure of decision tree\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "\n",
        "                filled=True, rounded=True,\n",
        "\n",
        "                special_characters=True,feature_names = feature_names,class_names=['lower_than_50K','higher_than_50K'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('ESG.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4RrADnB70Nf"
      },
      "source": [
        "### The economic meaning is posted on Sakai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqwM5LP9XkeF"
      },
      "source": [
        "# Add More Features \n",
        "#### (The economic interpretation for this part is attached in this notebook)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jUDi9z47uo7"
      },
      "source": [
        "feature_names=['race_num','sex_num','education.num']\n",
        "#feature_names=['race_num','sex_num','education.num','age','capital.gain','capital.loss']\n",
        "features=df[feature_names]\n",
        "targets=df['income']\n",
        "targets_names = targets.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZl2P1kJ8FS1"
      },
      "source": [
        "### Find the max_depth using cross validation score\n",
        "ScoreAll = []\n",
        "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
        "for i in range(1, 20):\n",
        "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=i, random_state=42)\n",
        "    score = cross_val_score(clf, features, targets, cv=cv).mean()\n",
        "    ScoreAll.append([i, score])\n",
        "ScoreAll = np.array(ScoreAll)\n",
        "max_score = np.where(ScoreAll==np.max(ScoreAll[:, 1]))[0][0]\n",
        "optimal_max_depth = ScoreAll[np.where(ScoreAll==np.max(ScoreAll[:, 1]))[0][0]][0]\n",
        "print(\"optimal max_depth and max score:\", ScoreAll[max_score])\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=[20, 5])\n",
        "plt.plot(ScoreAll[:, 0], ScoreAll[:, 1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkCmU87i8HhL"
      },
      "source": [
        "###training & test data split\r\n",
        "train_features, test_features, train_targets, test_targets = train_test_split(features, targets, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9_0IMGo8Q1Y"
      },
      "source": [
        "#####Optimizing Decision Tree Performance\r\n",
        "# Create Decision Tree classifer object\r\n",
        "clf = DecisionTreeClassifier(criterion='entropy', max_depth = optimal_max_depth,random_state=42)\r\n",
        "\r\n",
        "# Train Decision Tree Classifer\r\n",
        "clf = clf.fit(train_features,train_targets)\r\n",
        "\r\n",
        "#Predict the response for test dataset\r\n",
        "y_pred = clf.predict(test_features)\r\n",
        "\r\n",
        "# Compute test set accuracy  \r\n",
        "acc = accuracy_score(y_pred, test_targets)\r\n",
        "print(\"Test set accuracy: {:.4f}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIXustF48TTG"
      },
      "source": [
        "### Plot the figure of decision tree\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "\n",
        "                filled=True, rounded=True,\n",
        "\n",
        "                special_characters=True,feature_names = feature_names,class_names=['lower_than_50K','higher_than_50K'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('ESG.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUmDpbmr8VWu"
      },
      "source": [
        "## Economic Meaning:\n",
        "#### As is illustrated in the decision tree virtualization, education wage premium, gender pay gaps, and racial discrimination indeed exist in the U.S. labor market. Specifically, more education often leads to more income; males/white people tend to earn more than females/the black, which is congruent to the statistics collected by Stanford Center on Poverty & Inequality (2011). Those described income inequalities in the U.S. has increased substantially, with the overall level now approaching the extreme level that prevailed before the Great Depression (Horowitz, Igielnik, and Kochhar 2020). Concerning this social issue and based on my analysis of the decision tree model, implications could be proposed from two perspectives. Firstly, it is worthwhile for jobseekers to improve themselves through higher education or other channels. Further, the authorities should address inequalities in the labor market to reduce economic insecurity and enhance economic mobility. \n",
        "\n",
        "### Bibliography:\n",
        "#### https://www.mybib.com/j/LiterateMutePartridge\n"
      ]
    }
  ]
}